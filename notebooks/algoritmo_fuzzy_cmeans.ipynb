{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterização (Modelo Não Supervisionado Fuzzy C Means)\n",
    "Este notebook explora o algoritmo de aprendizado de máquina não supervisionado Fuzzy C Means. <br>\n",
    "O objetivo deste método é agrupar dados em diferentes grupos (clusters), em que cada dado pode pertencer a mais de um cluster simultanemante, sem o uso de rótulos prévios, e buscar tendências. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Instalação de bibliotecas\n",
    "Instala bibliotecas necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas==2.1.4 numpy==1.26.4 matplotlib==3.7.5 seaborn==0.13.2 scikit-learn==1.4.2 scikit-fuzzy==0.0.8 plotly==5.24.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Inicialização de bibliotecas\n",
    "Importa as bibliotecas necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import skfuzzy as fuzz\n",
    "import plotly.express as px\n",
    "\n",
    "from skfuzzy import cmeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "from sklearn.model_selection import ParameterGrid, GridSearchCV\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "# Configuração para mostrar todas as colunas no pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Configuração para exibir os gráficos diretamente no notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Importe do banco de dados via arquivo local\n",
    "Importação do DataFrame da base de dados da Unipar com a biblioteca pandas:\n",
    "\n",
    "Para rodar o notebook corretamente, será necessário importar o arquivo de banco de dados manualmente, pois ele não está incluído no repositório devido à presença de dados sensíveis.\n",
    "\n",
    "#### Passos para Importar o Banco de Dados no VS Code\n",
    "\n",
    "1. **Obtenha o Arquivo de Dados**:\n",
    "   - O arquivo `BASE DE SINISTRO UNIPAR BRADESCO.csv` deverá ser fornecido separadamente. Entre em contato com o responsável pelo projeto para receber o arquivo.\n",
    "\n",
    "2. **Posicione o Arquivo na Pasta Correta**:\n",
    "   - Após receber o arquivo, arraste-o para a mesma pasta onde o notebook está localizado em seu computador. Isso garante que o caminho relativo na função de leitura permaneça o mesmo e funcione corretamente.\n",
    "   \n",
    "3. **Verifique o Caminho do Arquivo**:\n",
    "   - O código de leitura do arquivo já está implementado no notebook e não precisa ser alterado:\n",
    "     ```python\n",
    "     df = pd.read_csv('BASE DE SINISTRO UNIPAR BRADESCO.csv', decimal=',')\n",
    "     ```\n",
    "   - Certifique-se de que o arquivo CSV esteja no mesmo diretório que o notebook para evitar problemas de caminho.\n",
    "\n",
    "4. **Rodar o Notebook**:\n",
    "   - Com o arquivo posicionado corretamente, execute o notebook normalmente. O pandas irá carregar os dados e você poderá seguir com a análise.\n",
    "\n",
    "**Nota**: Caso o arquivo não esteja na mesma pasta que o notebook, o código não será capaz de localizar o banco de dados, resultando em um erro. Portanto, é essencial que o arquivo seja arrastado para o diretório correto antes da execução.\n",
    "\n",
    "&ensp;Agora que você baixou os notebooks e o banco de dados, pode seguir para os próximos passos de execução, seja localmente ou no Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BASE DE SINISTRO UNIPAR BRADESCO.csv', decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pré-Processamento\n",
    "Como apresentado no notebook 'Pré-Processamento', as linhas a seguir executam várias etapas para limpar e organizar o banco de dados.<br>\n",
    "Os comentários no código explicam cada ação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza de dados\n",
    "\n",
    "# Tratamento de valores nulos\n",
    "df = df.dropna()\n",
    "# Correção do ponto faltante em 'UNIPAR INDUPA DO BRASIL S.A'\n",
    "df = df.replace({\"UNIPAR INDUPA DO BRASIL S.A\": \"UNIPAR INDUPA DO BRASIL S.A.\"})\n",
    "# Remoção de AGREGADO e DEPENDENTE\n",
    "df_remove_d = df.loc[(df['Elegibilidade Sinistro'] == 'DEPENDENTE') ]\n",
    "df = df.drop(df_remove_d.index)\n",
    "df_remove_a = df.loc[(df['Elegibilidade Sinistro'] == 'AGREGADO') ]\n",
    "df = df.drop(df_remove_a.index)\n",
    "# Tratamento de valores duplicados\n",
    "df = df.drop_duplicates(keep='last')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Codificação\n",
    "Este trecho de código realiza a codificação de colunas categóricas, transformando-as em valores numéricos para facilitar o uso no modelo<br>\n",
    "de machine learning. As colunas categóricas são mapeadas para índices numéricos, e o resultado é armazenado em um novo DataFrame.<br>\n",
    "Além disso, a coluna de data é convertida para o formato 'YYYYMMDD', e as colunas numéricas e de data são adicionadas ao DataFrame final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de colunas que serão codificadas (colunas categóricas)\n",
    "colunas_para_codificar = [\n",
    "    'Codigo Empresa Sinistro',\n",
    "    'Sexo Sinistro',\n",
    "    'Faixa-Etária Nova Sinistro',\n",
    "    'Descricao Plano Sinistro',\n",
    "    'Codigo Servico Sinistro',\n",
    "]\n",
    "\n",
    "# Colunas numéricas e de data que não precisam de codificação\n",
    "colunas_nao_codificadas = [\n",
    "    'Dt Data Sinistro',\n",
    "    'Valor Pago Sinistro',\n",
    "]\n",
    "\n",
    "# Para armazenar as novas colunas codificadas\n",
    "novas_colunas_codificadas = {}\n",
    "\n",
    "# Codificação das colunas categóricas\n",
    "for coluna in colunas_para_codificar:\n",
    "        unique_sorted_values = sorted(df[coluna].unique())\n",
    "        df[f'Codificada {coluna}'] = df[coluna].apply(lambda x: unique_sorted_values.index(x))\n",
    "        # Armazenar as novas colunas codificadas\n",
    "        novas_colunas_codificadas[f'Codificada {coluna}'] = df[f'Codificada {coluna}']\n",
    "\n",
    "# Criando um novo DataFrame com as novas colunas codificadas\n",
    "df_novo = pd.DataFrame(novas_colunas_codificadas)\n",
    "\n",
    "# Convertendo a coluna 'Dt Data Sinistro' para o formato 'YYYYMMDD' (Ano-Mês-Dia)\n",
    "df['Dt Data Sinistro'] = pd.to_datetime(df['Dt Data Sinistro'], format='%d/%m/%Y').dt.strftime('%Y%m%d')\n",
    "\n",
    "# Adicionando as colunas numéricas e de data ao DataFrame final\n",
    "for coluna in colunas_nao_codificadas:\n",
    "    df_novo[coluna] = df[coluna]\n",
    " \n",
    "df = df_novo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo as 10 primeiras linhas do novo DataFrame\n",
    "df.head(10).sort_values(by='Valor Pago Sinistro', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Detecção e Remoção de Outliers\n",
    "Esse bloco de código remove os outlier da coluna *Valor Pago Sinistro* aplicando o _IsolationForest_ com uma contaminação de 5%, criando um novo DataFrame chamado de `df_clean`. Além disso, ele padroniza as colunas numéricas e as armazena em uma nova variável `numeric_colums` apenas com as colunas numéricas do DataFrame para futuras análises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar IsolationForest para detectar outliers\n",
    "iso_forest = IsolationForest(contamination=0.05)  # 5% de contaminação, ajuste conforme necessário\n",
    "outliers = iso_forest.fit_predict(df[['Valor Pago Sinistro']])\n",
    "\n",
    "# Remover os outliers\n",
    "df_clean = df[outliers == 1]\n",
    "\n",
    "# Selecionar apenas as colunas numéricas para padronização\n",
    "numeric_columns = df_clean.select_dtypes(include=['float64', 'int64']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.describe().round(2) #Arredonda os dados com 2 casa decimais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Tratamento de Dados\n",
    "\n",
    "Este código padroniza as colunas numéricas no DataFrame `df_clean` após a remoção de outliers, utilizando o `StandardScaler` para ajustar os dados à média 0 e desvio padrão 1. \n",
    "\n",
    "A função `fit_transform` é aplicada para transformar as colunas numéricas, e o resultado é armazenado diretamente no DataFrame. Por fim, as primeiras linhas do DataFrame limpo e padronizado são exibidas com `df_clean.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronizar os dados após remover os outliers\n",
    "scaler = StandardScaler()\n",
    "df_clean.loc[:, numeric_columns] = scaler.fit_transform(df_clean[numeric_columns])  # Usando .loc para evitar o SettingWithCopyWarning\n",
    "\n",
    "# Mostrar as primeiras linhas do dataframe limpo e padronizado\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10).sort_values(by='Valor Pago Sinistro', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conversão e Extração de Componentes de Data\n",
    "\n",
    "Este código converte a coluna `Dt Data Sinistro` do DataFrame `df` para o formato datetime, utilizando o padrão 'YYYYMMDD'. Em seguida, extrai o componente do mês da data e o armazena em uma nova coluna chamada `Mes`. Se necessário, os valores dessa coluna são padronizados utilizando o `StandardScaler`, com o resultado armazenado na nova coluna `Mes_scaled`. O DataFrame resultante contém as colunas originais e as novas colunas derivadas da data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a coluna para datetime\n",
    "df['Dt Data Sinistro'] = pd.to_datetime(df['Dt Data Sinistro'], format='%Y%m%d')\n",
    "\n",
    "# Extrair componentes de dia\n",
    "df['Mes'] = df['Dt Data Sinistro'].dt.month\n",
    "\n",
    "# Padronizar (escalonar) os componentes se necessário\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df[[\"Mes_scaled\"]] = scaler.fit_transform(df[[\"Mes\"]])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Remoção de Colunas\n",
    "Este código remove as colunas `Mes` e `Dt Data Sinistro` do DataFrame `df`. A remoção dessas colunas é feita diretamente no DataFrame, utilizando o parâmetro `inplace=True`, o que garante que as alterações sejam aplicadas sem a necessidade de criar uma cópia do DataFrame. O resultado é um DataFrame que não contém mais as colunas especificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Mes'], inplace=True)\n",
    "\n",
    "df.drop(columns=['Dt Data Sinistro'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifcação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exploração de dados\n",
    "### Matriz de Disperção e Correlação\n",
    "Esse bloco gera uma matriz de gráficos de disperção (*scatter plots*) entre cada par de variáveis numéricas presentes no `df_clean`.<br>\n",
    "Usamos o pairplot para poder ter uma visualização mais rápida e intuitiva das relações entre as variáveis, facilitando a identificação de correlações que fazem mais sentido.\n",
    "\n",
    "A segunda célula calcula uma matriz de correlação para identificar o grau de influência entre duas features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Habilitar de acordo com a necessidade removendo o símbolo: #\n",
    "\n",
    "# Verificar a relação entre as variáveis\n",
    "# sns.pairplot(df_clean) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Habilitar de acordo com a necessidade removendo o símbolo: #\n",
    "\n",
    "# Calcular a matriz de correlação\n",
    "# sns.heatmap(df_clean.corr(), annot=True, cmap=\"coolwarm\", linewidths=0.5) \n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Modelo Fuzzy C Means\n",
    "Após tratar e padronizar os dados , a próxima etapa é aplicar o Fuzzy C Means (FCM). Nessa fase, o algoritmo é inicializado com o valor de n (clusters) escolhido.\n",
    "\n",
    "Esse bloco realiza a aplicação do modelo Fuzzy C-Means para rodar 1 vez com o objetivo de testar o modelo e visualiza, a partir de um gráfico, os clusters resultantes.<br>\n",
    "Definimos os seguintes hiperparâmetros do modelo:\n",
    "\n",
    "- n_clusters: Número de clusters a ser formado = 6\n",
    "- m: Fator de fuzzificação = 1.1, que controla a \"suavidade\" do pertencimento dos dados aos clusters\n",
    "- error: Critério de parada do algortimo = 0.01 \n",
    "- maxiter: Número máximo de iterações = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o número de clusters\n",
    "n_clusters = 6\n",
    "\n",
    "# Fuzzy C-Means clustering\n",
    "cntr, u, _, _, _, _, _ = fuzz.cluster.cmeans(\n",
    "    df.T, 6, 1.1, error=0.01, maxiter=1000)\n",
    "\n",
    "# Atribui os rótulos dos clusters\n",
    "cluster_labels = np.argmax(u, axis=0)\n",
    "\n",
    "# Adiciona os rótulos ao dataframe original\n",
    "df['cluster'] = cluster_labels\n",
    "\n",
    "# Exibe gráfico para visualização dos clusters\n",
    "plt.scatter(df['Mes_scaled'], df['Codificada Codigo Servico Sinistro'], c=df['cluster'], cmap='viridis')\n",
    "plt.scatter(cntr[:, 0], cntr[:, 1], c='red', marker='x')  # Centros dos clusters\n",
    "plt.title('Fuzzy C-Means Clustering')\n",
    "plt.xlabel('Mes_scaled')\n",
    "plt.ylabel('Codificada Codigo Servico Sinistro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de uma classe \n",
    "Esse bloco cria uma classe para o modelo Fuzzy C Means para poder rodar no Grid Search, fornecendo métodos para ajuste (fit), previsão (predict) e cálculo do silhouette score (uma métrica que avalia a qualidade dos clusters), com os hiperparâmetros definidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para Fuzzy C-Means\n",
    "\n",
    "class FuzzyCMeans(BaseEstimator, ClusterMixin):\n",
    "    def __init__(self, n_clusters=6, m=1.5, error=0.05, maxiter=300):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.m = m\n",
    "        self.error = error\n",
    "        self.maxiter = maxiter\n",
    "        self.labels_ = None\n",
    "        self.centers_ = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Fuzzy C-Means clustering\n",
    "        cntr, u, _, _, _, _, _ = fuzz.cluster.cmeans(\n",
    "            X.T, self.n_clusters, self.m, error=self.error, maxiter=self.maxiter\n",
    "        )\n",
    "        \n",
    "        # Obter rótulos de cluster\n",
    "        self.labels_ = np.argmax(u, axis=0)\n",
    "        self.centers_ = cntr\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.labels_\n",
    "\n",
    "    def silhouette_score(self, X):\n",
    "        return silhouette_score(X, self.labels_)\n",
    "    \n",
    "def silhouette_scorer(estimator, X):\n",
    "    labels = estimator.fit_predict(X)\n",
    "    # Evitar erro se apenas 1 cluster for formado\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        return silhouette_score(X, labels)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Finetunning de Hiperparâmetro (GridSearch)\n",
    "\n",
    "Esse bloco prepara os dados e define os parâmetros para realizar uma busca em grade (GridSearch), que tem como objetivo encontrar a melhor combinação de hiperparâmetros para o algoritmo. Inicialmente testamos algumas combinações de parâmetros, mas depois restringimos a somente uma combinação que conseguimos identificar como potencialmente ótimos. O objetivo final é aplicar esses parâmetros ajustados ao modelo e observar a performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para o GridSearch\n",
    "\n",
    "# Parâmetros ótimos para duas colunas: {'error': 0.05, 'm': 1.5, 'maxiter': 300, 'n_clusters': 7}\n",
    "X = df[['Codificada Codigo Servico Sinistro', 'Valor Pago Sinistro']].values\n",
    "\n",
    "# Parâmetros ótimos para df completo: {'error': 0.1, 'm': 1.1, 'maxiter': 1000, 'n_clusters': 6}\n",
    "X = df.values\n",
    "\n",
    "# # Define o grid de parâmetros para testar\n",
    "# param_grid = {\n",
    "#     'n_clusters': [6, 7],\n",
    "#     'm': [1.1, 1.5],\n",
    "#     'error': [0.01, 0.05],\n",
    "#     'maxiter': [300, 1000]\n",
    "# }\n",
    "\n",
    "# Definindo os parâmetros para busca\n",
    "param_grid = {\n",
    "    'n_clusters': [6],\n",
    "    'm': [1.1],\n",
    "    'error': [0.1],\n",
    "    'maxiter': [1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise de Hiperparâmetros com GridSearchCV \n",
    "\n",
    "Este código realiza uma busca em grade (GridSearchCV), com uma função de pontuação personalizada para encontrar os melhores parâmetros, e utiliza o silhouette score como métrica de avaliação da qualidade dos clusters (essa célula pode demorar de acordo com os parâmetros testados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando o GridSearchCV com uma função de pontuação personalizada\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=FuzzyCMeans(),\n",
    "    param_grid=param_grid,\n",
    "    scoring=silhouette_scorer,  # Usando a função silhouette_score como métrica\n",
    "    cv=5,\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "# Executando o GridSearch\n",
    "grid_search.fit(df)\n",
    "\n",
    "# Resultados\n",
    "print(\"Melhores parâmetros:\", grid_search.best_params_)\n",
    "print(\"Melhor Silhouette Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos Clusters\n",
    "\n",
    "Este bloco tem como objetivo visualizar os resultados do agrupamento Fuzzy C-Means utilizando os melhores parâmetros encontrados na busca em grade (GridSearchCV). Ele faz a predição dos clusters, cria um gráfico de dispersão (scatter plot) colorido por cluster e adiciona uma barra de cores com legendas baseadas nos clusters formados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os resultados com os melhores parâmetros\n",
    "best_model = grid_search.best_estimator_\n",
    "df['cluster'] = best_model.predict(X)\n",
    "\n",
    "# Visualizando os clusters\n",
    "scatter = plt.scatter(df['Mes_scaled'],df['Valor Pago Sinistro'], c=df['cluster'], cmap='Spectral', edgecolors='black')\n",
    "# plt.scatter(cntr[:, 0], cntr[:, 1], c='red', marker='x')  # Centros dos clusters\n",
    "plt.title('Fuzzy C-Means Clustering com Melhores Parâmetros')\n",
    "plt.xlabel('Valor Pago Sinistro')\n",
    "plt.ylabel('Codificada Codigo Servico Sinistro')\n",
    "\n",
    "# Lista de números de clusters\n",
    "clusters = np.unique(df['cluster'])\n",
    "\n",
    "# Criando a legenda com base nos clusters\n",
    "legend_labels = [f'Cluster {int(cluster)+1}' for cluster in clusters]\n",
    "\n",
    "# Criando a barra de cores para o gráfico\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_ticks(clusters)\n",
    "cbar.set_ticklabels(legend_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificação dos dados de um único cluster\n",
    "\n",
    "Esse bloco filtra o DataFrame para incluir apenas as linhas onde o valor na coluna **cluster** seja igual a 1, ou seja, isso irá mostrar apenas os dados que pertencem ao cluster 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_1_data = df[df['cluster'] == 1]\n",
    "\n",
    "cluster_1_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico do cluster 1 (baseado na faixa etária)\n",
    "\n",
    "Esse bloco realiza uma análise e visualização da distribuição de faixas etárias para os dados que pertencem ao cluster 1.<br>\n",
    "É realizado a contagem da frequência com que cada faixa etária, representada pela coluna 'Codificada Faixa-Etária Nova Sinistro', aparece no cluster 1.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_1_data = df[df['cluster'] == 1] \n",
    "\n",
    "service_counts = cluster_1_data['Codificada Faixa-Etária Nova Sinistro'].value_counts()\n",
    "\n",
    "# Plotando o gráfico de barras\n",
    "plt.bar(service_counts.index, service_counts.values)\n",
    "\n",
    "# Título e rótulos dos eixos\n",
    "plt.title('Distribuição de Faixa-Etária - Cluster 1')\n",
    "plt.xlabel('Faixa-Etária')\n",
    "plt.ylabel('Frequência')\n",
    "\n",
    "# Exibindo o gráfico\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos de distribuição de Faixa Etária em cada cluster\n",
    "\n",
    "Gera uma visualização gráfica da distribuição de faixas etárias em todos os 6 clusters, com base na coluna 'Codificada Faixa-Etária Nova Sinistro'. Usamos essa visualização para analisar como as faixas etárias estão distribuídas em cada cluster que o modelo fez e possivelmente tirar algum *insight* relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir número de clusters (ajustar de acordo com os dados)\n",
    "num_clusters = 6\n",
    "\n",
    "# Obter todas as categorias únicas de \"Codificada Faixa-Etária Nova Sinistro\"\n",
    "faixas_etarias = df['Codificada Faixa-Etária Nova Sinistro'].unique()\n",
    "\n",
    "# Criar um colormap fixo associando cada faixa-etária a uma cor\n",
    "cmap = plt.get_cmap('tab10')  # Colormap com 10 cores distintas, pode-se usar outros como 'viridis', 'Set3', etc.\n",
    "color_mapping = {faixa: cmap(i % 10) for i, faixa in enumerate(faixas_etarias)}  # Mapeamento faixa-etária -> cor\n",
    "\n",
    "# Criar uma figura com subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))  # 2 linhas e 3 colunas de gráficos\n",
    "\n",
    "# Iterar sobre cada cluster\n",
    "for i in range(num_clusters):\n",
    "    cluster_data = df[df['cluster'] == i]  # Filtrar os dados do cluster atual\n",
    "    service_counts = cluster_data['Codificada Faixa-Etária Nova Sinistro'].value_counts()  # Contar os valores\n",
    "    \n",
    "    # Selecionar o eixo correto (usar i//3 para linha e i%3 para coluna)\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    \n",
    "    # Gerar cores para as barras com base na faixa-etária\n",
    "    bar_colors = [color_mapping[faixa] for faixa in service_counts.index]\n",
    "    \n",
    "    # Plotar o gráfico de barras no eixo correspondente\n",
    "    ax.bar(service_counts.index, service_counts.values, color=bar_colors)\n",
    "    ax.set_title(f'Distribuição de Faixa Etária por Cluster {i+1}')\n",
    "    ax.set_xlabel('Faixa Etária')\n",
    "    ax.set_ylabel('Frequência')\n",
    "\n",
    "# Adicionar legenda com as faixas-etárias e suas cores\n",
    "handles = [plt.Rectangle((0,0),1,1, color=color_mapping[faixa]) for faixa in faixas_etarias]\n",
    "labels = faixas_etarias\n",
    "fig.legend(handles, labels, title=\"Faixa Etária\", loc='upper center', ncol=len(faixas_etarias))\n",
    "\n",
    "# Ajustar layout para evitar sobreposição de textos\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Deixar espaço no topo para a legenda\n",
    "\n",
    "# Exibir os gráficos\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Cálculo de métricas\n",
    "\n",
    "Aqui é realizado o cálculo das métricas escolhidas: Silhouette Score, Davis-Bouldin Index e Calinski-Harabasz Index. Elas ajudam a verificar se a formação dos *clusters* foi bem-sucedida, com base na qualidade da segmentação obtida. O resultado dessas métricas sozinho não deve ser a única maneira de avaliar se o modelo de fato é o melhor, estamos levando em consideração como os *clusters* foram segmentados pelo algoritmo para ter certeza de que as divisões feitas realmente fazem sentido para o projeto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define os dados pra o grid search e os parametros \n",
    "# Preparar dados para clustering\n",
    "X = df[['Valor Pago Sinistro', 'Codificada Codigo Servico Sinistro']].values\n",
    "\n",
    "# Inicializando o modelo Fuzzy C-Means com os parâmetros fornecidos\n",
    "fcm = FuzzyCMeans(n_clusters=6, m=1.1, error=0.05, maxiter=1000)\n",
    "fcm.fit(X) \n",
    "\n",
    "# Adicionando rótulos ao DataFrame\n",
    "df['cluster'] = fcm.predict(X)\n",
    "\n",
    "# Calculando o Silhouette Score\n",
    "silhouette_avg = silhouette_score(X, df['cluster'])\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "# Calculando o Davies-Bouldin Index\n",
    "dbi = davies_bouldin_score(X, df['cluster'])\n",
    "print(f\"Davies-Bouldin Index: {dbi}\")\n",
    "\n",
    "# Calculando o Calinski-Harabasz Index\n",
    "chi = calinski_harabasz_score(X, df['cluster'])\n",
    "print(f\"Calinski-Harabasz Index: {chi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Outras análises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico 3D \n",
    "\n",
    "Esse bloco gera uma visualização dos resultados do modelo Fuzzy C Means, em três dimensões, com base nos melhores parâmetros encontrados pelo GridSearch (GridSearchCV). Ele cria um gráfico tridimensional, onde as variáveis são mapeadas para os eixos X, Y e Z, e os pontos são coloridos de acordo com o cluster ao qual pertencem. As variáveis escolhidas foram as colunas `Codificada Codigo Servico Sinistro` (eixo X), `Valor Pago Sinistro` (eixo Y) e `Codificada Faixa-Etária Nova Sinistro` (eixo Z).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os resultados com os melhores parâmetros\n",
    "best_model = grid_search.best_estimator_\n",
    "df['cluster'] = best_model.predict(X)\n",
    "\n",
    "# Definindo as variáveis para o gráfico 3D\n",
    "x = df['Codificada Codigo Servico Sinistro']\n",
    "y = df['Valor Pago Sinistro']\n",
    "z = df['Codificada Faixa-Etária Nova Sinistro']  # Use a variável que faz sentido para o z\n",
    "\n",
    "# Criando a figura 3D\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plotando os pontos\n",
    "scatter = ax.scatter(x, y, z, c=df['cluster'], cmap='Spectral', edgecolors='black')\n",
    "\n",
    "# Adicionando título e rótulos aos eixos\n",
    "ax.set_title('Fuzzy C-Means Clustering com Melhores Parâmetros')\n",
    "ax.set_xlabel('Codificada Codigo Servico Sinistro')\n",
    "ax.set_ylabel('Valor Pago Sinistro')\n",
    "ax.set_zlabel('Codificada Faixa-Etária Nova Sinistro')\n",
    "\n",
    "# Criando a barra de cores para o gráfico\n",
    "cbar = plt.colorbar(scatter)\n",
    "clusters = np.unique(df['cluster'])\n",
    "cbar.set_ticks(clusters)\n",
    "cbar.set_ticklabels([f'Cluster {int(cluster)+1}' for cluster in clusters])\n",
    "\n",
    "# Exibindo o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico 3D Interativo\n",
    "\n",
    "Este código utiliza a biblioteca Plotly Express para criar um gráfico 3D interativo, que visualiza os resultados do modelo Fuzzy C-Means após a busca dos melhores parâmetros por meio do GridSearchCV. Utilizamos as mesmas 3 variáveis do gráfico anterior. Escolhemos criar esses gráficos para ajudar na compreensão das divisões dos cluster e tentar extrair alguns *insights* que possam ser relevantes para nosso projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os resultados com os melhores parâmetros\n",
    "best_model = grid_search.best_estimator_\n",
    "df['cluster'] = best_model.predict(X)\n",
    "\n",
    "# Criando o gráfico 3D interativo\n",
    "fig_3d = px.scatter_3d(\n",
    "    df, \n",
    "    x='Codificada Codigo Servico Sinistro', \n",
    "    y='Valor Pago Sinistro', \n",
    "    z='Codificada Faixa-Etária Nova Sinistro',\n",
    "    color='cluster',\n",
    "    title='Fuzzy C-Means Clustering com Melhores Parâmetros',\n",
    "    color_continuous_scale='Spectral',\n",
    "    \n",
    ")\n",
    "\n",
    "# Atualizando os rótulos dos eixos e o tamanho dos marcadores\n",
    "fig_3d.update_traces(marker=dict(size=4))  # Reduzindo o tamanho dos pontos\n",
    "\n",
    "# Atualizando o layout para aumentar o tamanho do gráfico\n",
    "fig_3d.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='Codificada Codigo Servico Sinistro',\n",
    "        yaxis_title='Valor Pago Sinistro',\n",
    "        zaxis_title='Codificada Faixa-Etária Nova Sinistro'\n",
    "    ),\n",
    "    width=1200,  # Largura do gráfico\n",
    "    height=800   # Altura do gráfico\n",
    ")\n",
    "\n",
    "max_range = np.array([x.max()-x.min(), y.max()-y.min(), z.max()-z.min()]).max() / 2.0\n",
    "mid_x = (x.max()+x.min()) * 0.5\n",
    "mid_y = (y.max()+y.min()) * 0.5\n",
    "mid_z = (z.max()+z.min()) * 0.5\n",
    "ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "# Mostrando o gráfico\n",
    "fig_3d.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
